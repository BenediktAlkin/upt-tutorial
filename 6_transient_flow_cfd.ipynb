{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup environment\n",
    "try:\n",
    "    # setup colab\n",
    "    import google.colab\n",
    "    !pip install kappamodules\n",
    "    !pip install torch_geometric\n",
    "    import torch\n",
    "    print(torch.__version__)\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.get_device_name(device)\n",
    "    # might need to torch version to the one installed in colab\n",
    "    !pip install torch_scatter torch_cluster -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
    "    # checkout repo\n",
    "    !git clone https://github.com/BenediktAlkin/upt-tutorial.git\n",
    "    %cd upt-tutorial\n",
    "except ImportError:\n",
    "    # setup with own server\n",
    "    import torch\n",
    "    print(torch.__version__)\n",
    "    device = torch.device(\"cuda:7\")\n",
    "    print(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6 Transient Flow CFD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab049803f2bedcb3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from upt.collators.simulation_collator import SimulationCollator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8d9add7a6449ac2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from upt.datasets.simulation_dataset import SimulationDataset\n",
    "\n",
    "# initialize dataset\n",
    "train_dataset = SimulationDataset(\n",
    "    root=\"./data/simulation\",\n",
    "    # how many inputs to use for training\n",
    "    num_inputs=8192,\n",
    "    # how many outputs to use for training\n",
    "    num_outputs=4096,\n",
    "    # mode\n",
    "    mode=\"train\",\n",
    ")\n",
    "rollout_dataset = SimulationDataset(\n",
    "    root=\"./data/simulation\",\n",
    "    # use all inputs for rollout\n",
    "    num_inputs=float(\"inf\"),\n",
    "    # use all outputs for rollout\n",
    "    num_outputs=float(\"inf\"),\n",
    "    # mode\n",
    "    mode=\"train\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "330b469f1e08edd0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "dim = 192  # ~6M parameter model\n",
    "num_heads = 3\n",
    "epochs = 10\n",
    "batch_size = 256"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e50b52f5fd94f4c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from upt.models.upt import UPT\n",
    "from upt.models.approximator import Approximator\n",
    "from upt.models.decoder_perceiver import DecoderPerceiver\n",
    "from upt.models.encoder_supernodes import EncoderSupernodes\n",
    "from upt.models.conditioner_timestep import ConditionerTimestep\n",
    "\n",
    "# initialize model\n",
    "model = UPT(\n",
    "    conditioner=ConditionerTimestep(\n",
    "        dim=dim,\n",
    "        num_timesteps=train_dataset.num_timesteps,\n",
    "    ),\n",
    "    encoder=EncoderSupernodes(\n",
    "        # simulation has 3 inputs: 2D velocity + pressure\n",
    "        input_dim=3,\n",
    "        # 2D dataset\n",
    "        ndim=2,\n",
    "        # positions are rescaled to [0, 200]\n",
    "        radius=5,\n",
    "        # in regions where there are a lot of mesh cells, it would result in supernodes having a lot of\n",
    "        # connections to nodes. but since we sample the supernodes uniform, we also have a lot of supernodes\n",
    "        # in dense regions, so we can simply limit the maximum amount of connections to each supernodes\n",
    "        # to avoid an extreme amount of edges\n",
    "        max_degree=32,\n",
    "        # dimension for the supernode pooling -> use same as ViT-T latent dim\n",
    "        gnn_dim=dim,\n",
    "        # ViT-T latent dimension\n",
    "        enc_dim=dim,\n",
    "        enc_num_heads=num_heads,\n",
    "        # ViT-T has 12 blocks -> parameters are split evenly among encoder/approximator/decoder\n",
    "        enc_depth=4,\n",
    "        # downsample to 128 latent tokens for fast training\n",
    "        perc_dim=dim,\n",
    "        perc_num_heads=num_heads,\n",
    "        num_latent_tokens=128,\n",
    "    ),\n",
    "    approximator=Approximator(\n",
    "        # tell the approximator the dimension of the input (perc_dim or enc_dim of encoder)\n",
    "        input_dim=dim,\n",
    "        # as in ViT-T\n",
    "        dim=dim,\n",
    "        num_heads=num_heads,\n",
    "        # ViT-T has 12 blocks -> parameters are split evenly among encoder/approximator/decoder\n",
    "        depth=4,\n",
    "    ),\n",
    "    decoder=DecoderPerceiver(\n",
    "        # tell the decoder the dimension of the input (dim of approximator)\n",
    "        input_dim=dim,\n",
    "        # 2D velocity + pressure\n",
    "        output_dim=3,\n",
    "        # simulation is 2D\n",
    "        ndim=2,\n",
    "        # as in ViT-T\n",
    "        dim=dim,\n",
    "        num_heads=num_heads,\n",
    "        # ViT-T has 12 blocks -> parameters are split evenly among encoder/approximator/decoder\n",
    "        depth=4,\n",
    "        # we assume num_outputs to be constant so we can simply reshape the dense result into a sparse tensor\n",
    "        unbatch_mode=\"dense_to_sparse_unpadded\",\n",
    "    ),\n",
    ")\n",
    "model = model.to(device)\n",
    "print(f\"parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96e1e89e84bd3b27"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# setup dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=SimulationCollator(num_supernodes=512, deterministic=False),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d51a3eed0e5d0b1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# initialize optimizer and learning rate schedule (linear warmup for first 10% -> linear decay)\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.05)\n",
    "total_updates = len(train_dataloader) * epochs\n",
    "warmup_updates = int(total_updates * 0.1)\n",
    "lrs = torch.concat(\n",
    "    [\n",
    "        # linear warmup\n",
    "        torch.linspace(0, optim.defaults[\"lr\"], warmup_updates),\n",
    "        # linear decay\n",
    "        torch.linspace(optim.defaults[\"lr\"], 0, total_updates - warmup_updates),\n",
    "    ],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93cb7e49412b6c70"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# train model\n",
    "update = 0\n",
    "pbar = tqdm(total=total_updates)\n",
    "pbar.update(0)\n",
    "pbar.set_description(\"train_loss: ?????\")\n",
    "train_losses = []\n",
    "for _ in range(epochs):\n",
    "    # train for an epoch\n",
    "    for batch in train_dataloader:\n",
    "        # schedule learning rate\n",
    "        for param_group in optim.param_groups:\n",
    "            param_group[\"lr\"] = lrs[update]\n",
    "\n",
    "        # forward pass\n",
    "        y_hat = model(\n",
    "            input_feat=batch[\"input_feat\"].to(device),\n",
    "            input_pos=batch[\"input_pos\"].to(device),\n",
    "            supernode_idxs=batch[\"supernode_idxs\"].to(device),\n",
    "            batch_idx=batch[\"batch_idx\"].to(device),\n",
    "            output_pos=batch[\"output_pos\"].to(device),\n",
    "        )\n",
    "        y = batch[\"output_feat\"].to(device)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update step\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # status update\n",
    "        update += 1\n",
    "        pbar.update()\n",
    "        pbar.set_description(f\"train_loss: {loss.item():.4f}\")\n",
    "        train_losses.append(loss.item())\n",
    "pbar.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70ba40b5486e2408"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have a trained model, we can try to generate a simulation. In order to simulate new simulations, one would need to train on a lot of different simulations, but as we only train on 1 simulation for this tutorial, we'll generate the rollout of this simulation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# setup dataloader\n",
    "rollout_dataloader = DataLoader(\n",
    "    dataset=rollout_dataset,\n",
    "    batch_size=1,\n",
    "    collate_fn=SimulationCollator(num_supernodes=512, deterministic=True),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get rollout batch\n",
    "batch = next(iter(rollout_dataloader))\n",
    "\n",
    "# rollout\n",
    "y_hat = model.rollout(\n",
    "    input_feat=batch[\"input_feat\"].to(device),\n",
    "    input_pos=batch[\"input_pos\"].to(device),\n",
    "    supernode_idxs=batch[\"supernode_idxs\"].to(device),\n",
    "    batch_idx=batch[\"batch_idx\"].to(device),\n",
    "    output_pos=batch[\"output_pos\"].to(device),\n",
    ")\n",
    "# get ground truth\n",
    "y = batch[\"output_feat\"]\n",
    "\n",
    "# extract plot data\n",
    "output_pos = batch[\"output_pos\"]\n",
    "y_hat = [y_hat[i].cpu() for i in range(len(y_hat))]\n",
    "\n",
    "# generate pngs\n",
    "# for i in range(len(y_hat)):\n",
    "#     plt.clf()\n",
    "#     fig, (ax0, ax1, ax2) = plt.subplots(3, 1)\n",
    "#     # particles\n",
    "#     if output_pos[i].shape[0] == 1:\n",
    "#         px = output_pos[i][0, :, 0]\n",
    "#         pz = output_pos[i][0, :, 2]\n",
    "#     else:\n",
    "#         px = output_pos[i][:, 0]\n",
    "#         pz = output_pos[i][:, 2]\n",
    "#     c0 = output_gt[i].abs().mean(dim=1)\n",
    "#     c1 = output_pred[i].abs().mean(dim=1)\n",
    "#     c2 = (output_gt[i] - output_pred[i]).abs().mean(dim=1)\n",
    "#     cmax = 5\n",
    "#     # cmax = max(c0.max(), c1.max())\n",
    "#     ax0.scatter(px, pz, c=c0, vmin=0, vmax=cmax, s=3)\n",
    "#     scatter1 = ax1.scatter(px, pz, c=c1, vmin=0, vmax=cmax, s=3)\n",
    "#     scatter2 = ax2.scatter(px, pz, c=c2, vmin=0, vmax=2, s=3)\n",
    "#     # save\n",
    "#     ax0.set_title(\"target\")\n",
    "#     ax1.set_title(\"pred\")\n",
    "#     ax2.set_title(\"delta\")\n",
    "#     ax0.set_xticks(ticks=[])\n",
    "#     ax0.set_yticks(ticks=[])\n",
    "#     ax1.set_xticks(ticks=[])\n",
    "#     ax1.set_yticks(ticks=[])\n",
    "#     ax2.set_xticks(ticks=[])\n",
    "#     ax2.set_yticks(ticks=[])\n",
    "#     plt.colorbar(scatter1, ax=[ax0, ax1], orientation=\"vertical\")\n",
    "#     plt.colorbar(scatter2, ax=ax2, orientation=\"vertical\")\n",
    "#     plt.savefig(self.out_png / f\"{self.update_counter.cur_checkpoint}_{index.item():04d}_{i:04d}.png\")\n",
    "#     plt.close()\n",
    "#     if i > 200:\n",
    "#         break\n",
    "#\n",
    "# # generate gifs\n",
    "# def load_pil(uri):\n",
    "#     temp = Image.open(uri)\n",
    "#     img = temp.copy()\n",
    "#     temp.close()\n",
    "#     return img\n",
    "#\n",
    "# imgs = [\n",
    "#     load_pil(self.out_png / f\"{self.update_counter.cur_checkpoint}_{index.item():04d}_{i:04d}.png\")\n",
    "#     for i in range(min(200, len(output_pred)))\n",
    "# ]\n",
    "# imgs[0].save(\n",
    "#     fp=self.out_gif / f\"{self.update_counter.cur_checkpoint}_{index.item():04d}.gif\",\n",
    "#     format=\"GIF\",\n",
    "#     append_images=imgs[1:],\n",
    "#     save_all=True,\n",
    "#     duration=100,\n",
    "#     loop=0,\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}